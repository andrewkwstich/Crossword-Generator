{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16csfcJ2TNd9",
        "outputId": "b4bfddf2-83c1-4321-d04b-e5711a036a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "16csfcJ2TNd9"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7XlS7hhWXN2",
        "outputId": "bcafb30a-5da8-4fa3-dfdf-d352b1aefa45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 64.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ],
      "id": "X7XlS7hhWXN2"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnpYTlc07qjx",
        "outputId": "8e9be5d3-c6eb-47a2-a11b-2e6e7a082ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wordfreq\n",
            "  Downloading wordfreq-3.0.2-py3-none-any.whl (56.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 56.8 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2021.7.6 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (2022.6.2)\n",
            "Collecting ftfy>=6.1\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (3.3.0)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.7/dist-packages (from wordfreq) (1.0.4)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy>=6.1->wordfreq) (0.2.5)\n",
            "Installing collected packages: ftfy, wordfreq\n",
            "Successfully installed ftfy-6.1.1 wordfreq-3.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wordfreq"
      ],
      "id": "YnpYTlc07qjx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ae4659-c947-43a9-ab5b-7668435d297d",
        "outputId": "eec4062f-e516-47c5-fb3c-f2dfd26ae454"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import regex as re\n",
        "import string\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, AdamW, get_linear_schedule_with_warmup, GPTNeoForCausalLM\n",
        "import torch\n",
        "torch.manual_seed(14)\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "import nltk\n",
        "from wordfreq import word_frequency\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "nltk.download('punkt')\n",
        "from tqdm import tqdm, trange"
      ],
      "id": "d8ae4659-c947-43a9-ab5b-7668435d297d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v7z6L6sII44"
      },
      "outputs": [],
      "source": [
        "category_list = [\"(wordplay)\", \"(anagram)\", \"(abbreviation)\"]"
      ],
      "id": "8v7z6L6sII44"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrfGfXGlBtNx"
      },
      "outputs": [],
      "source": [
        "def discard_low_freq(words, category_list=category_list, threshold=5e-05):\n",
        "    words = str(words)\n",
        "    tokenized = words.translate(str.maketrans('', '', string.punctuation)).split()\n",
        "    freqs = [(word, word_frequency(word, \"en\")) for word in tokenized]\n",
        "    for word, freq in freqs:\n",
        "        if freq < threshold and \"(\"+word+\")\" not in category_list:\n",
        "            return np.NaN\n",
        "    return True"
      ],
      "id": "zrfGfXGlBtNx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiouTDR9O2Cg"
      },
      "outputs": [],
      "source": [
        "def discard_low_freq_df(df):\n",
        "    return df.iloc[df[[\"answer\", \"clue\"]].applymap(discard_low_freq).dropna().index].reset_index()"
      ],
      "id": "TiouTDR9O2Cg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63447a12-4d2f-4880-b929-2e3d738880f3"
      },
      "outputs": [],
      "source": [
        "train = discard_low_freq_df(pd.read_csv(path+\"train.csv\"))\n",
        "dev = discard_low_freq_df(pd.read_csv(path+\"valid.csv\"))"
      ],
      "id": "63447a12-4d2f-4880-b929-2e3d738880f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zU_iuEdX5JX"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/Crossword-Generator/'"
      ],
      "id": "1zU_iuEdX5JX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eac700fc-9691-46f0-a776-287179f5b50e"
      },
      "outputs": [],
      "source": [
        "cache_dir = path + \"tmp/\"\n",
        "checkpoints = path + \"checkpoints/\""
      ],
      "id": "eac700fc-9691-46f0-a776-287179f5b50e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-wIj678gTuE"
      },
      "outputs": [],
      "source": [
        "model_str = \"EleutherAI/gpt-neo-1.3B\"\n",
        "model_dict = {\"EleutherAI/gpt-neo-1.3B\":GPTNeoForCausalLM, \"gpt2\":GPT2LMHeadModel}\n",
        "model_type = model_dict[model_str]"
      ],
      "id": "9-wIj678gTuE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f158b5c8-17b3-4a66-9b98-a3684a1cc590",
        "outputId": "6cc0e585-fe96-4e8e-9214-bb0b7e12c85f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(model_str, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>', cache_dir=cache_dir)\n",
        "model = model_type.from_pretrained(model_str, cache_dir=cache_dir)"
      ],
      "id": "f158b5c8-17b3-4a66-9b98-a3684a1cc590"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi8Jn87ceuoX",
        "outputId": "d0e235cf-45a4-4704-9046-15aa150a4cd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTNeoForCausalLM(\n",
              "  (transformer): GPTNeoModel(\n",
              "    (wte): Embedding(50259, 2048)\n",
              "    (wpe): Embedding(2048, 2048)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (12): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (13): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (14): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (15): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (16): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (17): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (18): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (19): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (20): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (21): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (22): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (23): GPTNeoBlock(\n",
              "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTNeoAttention(\n",
              "          (attention): GPTNeoSelfAttention(\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPTNeoMLP(\n",
              "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=50259, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.resize_token_embeddings(len(tokenizer))\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()"
      ],
      "id": "zi8Jn87ceuoX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkouP0U3S6Un"
      },
      "outputs": [],
      "source": [
        "category_string = str(tuple(category_list)).replace(\", \", \"|\").replace(\"'\",\"\")\n",
        "category_dict = {}\n",
        "for word in category_list:\n",
        "    category_dict[word] = []"
      ],
      "id": "lkouP0U3S6Un"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8931d6a-65f0-4b59-84e8-80344ed9f71a"
      },
      "outputs": [],
      "source": [
        "train_list_analogy = []\n",
        "analogy_length = 100000\n",
        "\n",
        "for i in range(0, analogy_length, 2):\n",
        "    try:\n",
        "        i_match = re.search(\"\\({}\\)\".format(category_string), train[\"clue\"][i])\n",
        "        next_match = re.search(\"\\({}\\)\".format(category_string), train[\"clue\"][i+1])\n",
        "        if not i_match and not next_match:\n",
        "            train_list_analogy.append(\"Crossword clue for \" + train[\"answer\"][i] + \": \" + train[\"clue\"][i] + \". Crossword clue for \" + train[\"answer\"][i+1] + \": \" + train[\"clue\"][i+1])\n",
        "        elif i_match and i_match[0] in category_dict:\n",
        "            category_dict[i_match[0]].append(i)\n",
        "        elif next_match and next_match[0] in category_dict:\n",
        "            category_dict[next_match[0]].append(i+1)\n",
        "        else:\n",
        "            train_list_analogy.append(\"Crossword clue for \" + train[\"answer\"][i] + \": \" + train[\"clue\"][i] + \". Crossword clue for \" + train[\"answer\"][i+1] + \": \" + train[\"clue\"][i+1])\n",
        "    except:\n",
        "        print(i)\n",
        "        pass\n",
        "for category in category_dict.values():\n",
        "    for i in range(0, len(category), 2):\n",
        "        try:\n",
        "            train_list_analogy.append(\"Crossword clue for \" + train[\"answer\"][category[i]] + \": \" + train[\"clue\"][category[i]] + \". Crossword clue for \" + train[\"answer\"][category[i+1]] + \": \" + train[\"clue\"][category[i+1]])\n",
        "        except:\n",
        "            pass"
      ],
      "id": "e8931d6a-65f0-4b59-84e8-80344ed9f71a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3WEaWvRTGG8",
        "outputId": "102f2575-10ef-4a27-e7eb-cfea4acff8be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "48107"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_list_analogy)"
      ],
      "id": "V3WEaWvRTGG8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLoQP74icJNF"
      },
      "outputs": [],
      "source": [
        "train_list_single = []\n",
        "num_train_examples = int(200000)  # = len(train) if using all data\n",
        "for i in range(analogy_length, num_train_examples, 1):\n",
        "    try:\n",
        "        train_list_single.append(\"Crossword clue for \" + train[\"answer\"][i] + \": \" + train[\"clue\"][i])\n",
        "    except:\n",
        "        pass"
      ],
      "id": "LLoQP74icJNF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j8q1DJbXbZZ"
      },
      "outputs": [],
      "source": [
        "dev_list = []\n",
        "num_dev_examples = int(25000)  # = len(dev) if using all data\n",
        "for i in range(num_dev_examples):\n",
        "    try:\n",
        "        dev_list.append(\"Crossword clue for \" + dev[\"answer\"][i] + \": \" + dev[\"clue\"][i])\n",
        "    except:\n",
        "        pass"
      ],
      "id": "6j8q1DJbXbZZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9258d49-67e4-4a76-9128-433bb144110b"
      },
      "outputs": [],
      "source": [
        "class GPTDataset(Dataset):\n",
        "\n",
        "    def __init__(self, txt_list, tokenizer, max_length=30):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "\n",
        "        for txt in txt_list:\n",
        "\n",
        "            encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx] "
      ],
      "id": "f9258d49-67e4-4a76-9128-433bb144110b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fde3e125-fc23-43e2-9515-252ddb86363c"
      },
      "outputs": [],
      "source": [
        "train_dataset_analogy = GPTDataset(train_list_analogy, tokenizer)\n",
        "train_dataset_single = GPTDataset(train_list_single, tokenizer)\n",
        "dev_dataset = GPTDataset(dev_list, tokenizer)\n",
        "\n",
        "train_dataloader_analogy = DataLoader(\n",
        "            train_dataset_analogy,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset_analogy), # Select batches randomly\n",
        "            batch_size = 2 # Trains with this batch size.\n",
        "        )\n",
        "train_dataloader_single = DataLoader(\n",
        "            train_dataset_single,\n",
        "            sampler = RandomSampler(train_dataset_single),\n",
        "            batch_size = 2\n",
        "        )\n",
        "dev_dataloader = DataLoader(\n",
        "            dev_dataset,\n",
        "            sampler = RandomSampler(dev_dataset),\n",
        "            batch_size = 2\n",
        "        )"
      ],
      "id": "fde3e125-fc23-43e2-9515-252ddb86363c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e39584c-b6fb-451c-9008-c0aeda8b138d"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "total_steps = len(train_dataset_analogy) + len(train_dataset_single) * (epochs-1)\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 1000"
      ],
      "id": "8e39584c-b6fb-451c-9008-c0aeda8b138d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35e131ad-f625-45aa-8b62-636a4d8aa0af",
        "outputId": "a7562a59-044a-42a4-b664-b0ee71ae139d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "id": "35e131ad-f625-45aa-8b62-636a4d8aa0af"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCnKIcYNWs_5"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "id": "GCnKIcYNWs_5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b94ac50-9e40-4200-a83a-133dab85d1ad",
        "outputId": "c8828b85-08bc-4f43-b48f-b5b34f377eaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch 1,000  of  24,054. Loss: 2.892059087753296.   Elapsed: 0:02:33.\n",
            "Crossword clue for step: One of 39 in an old movie. Crossword clue for agent: Made a band\n",
            "Crossword clue for did: Carried through on. Crossword clue for of course: Night.\n",
            "  Batch 2,000  of  24,054. Loss: 2.2793357372283936.   Elapsed: 0:05:07.\n",
            "Crossword clue for net gain: Final profit. Crossword clue for de co: It makes sense before a lot on it\n",
            "Crossword clue for nearly: More or less. Crossword clue for return: '___!'\n",
            "  Batch 3,000  of  24,054. Loss: 2.3121321201324463.   Elapsed: 0:07:40.\n",
            "Crossword clue for high: Weather map mark. Crossword clue for word: They's for \"up, what!\"\n",
            "Crossword clue for i took: ___ a trip on a train.... Crossword clue for how: 'Yes already!'\n",
            "  Batch 4,000  of  24,054. Loss: 2.3873767852783203.   Elapsed: 0:10:13.\n",
            "Crossword clue for arts: Industrial ___ (school subject). Crossword clue for quite a few: Not many in (wordplay)\n",
            "Crossword clue for a re: \"So there you ___\". Crossword clue for blue: Kind of pay, probably\n",
            "  Batch 5,000  of  24,054. Loss: 2.2477526664733887.   Elapsed: 0:12:47.\n",
            "Crossword clue for needs: Wants. Crossword clue for win: No.!\" ly.,..'s,\n",
            "Crossword clue for a vote: Cast. Crossword clue for at home: '!\"\n",
            "  Batch 6,000  of  24,054. Loss: 2.0219829082489014.   Elapsed: 0:15:21.\n",
            "Crossword clue for steps out: Leaves the office for a bit. Crossword clue for path: Male, with a major.\n",
            "Crossword clue for men: See 7. Crossword clue for ride: Put not a leading day\n",
            "  Batch 7,000  of  24,054. Loss: 2.047417640686035.   Elapsed: 0:17:53.\n",
            "Crossword clue for walk to: Reach on foot. Crossword clue for area: What one goes's one could make a driver is not\n",
            "Crossword clue for one: Low number.. Crossword clue for ask not: \"No me could ___?\"\n",
            "  Batch 8,000  of  24,054. Loss: 2.6278493404388428.   Elapsed: 0:20:25.\n",
            "Crossword clue for get fat: Change shape, in a way. Crossword clue for pair: Word after play and part or director\n",
            "Crossword clue for train: Work out. Crossword clue for site: Football figure. \n",
            "  Batch 9,000  of  24,054. Loss: 2.1394975185394287.   Elapsed: 0:22:56.\n",
            "Crossword clue for home: First website page. Crossword clue for been: 'Oh't...\n",
            "Crossword clue for heat: See 23 Across. Crossword clue for voice: \"___ is good\" \n",
            "  Batch 10,000  of  24,054. Loss: 2.8130946159362793.   Elapsed: 0:25:27.\n",
            "Crossword clue for for go: Green is the way to begin 15 across. Crossword clue for rate: From the word, in a little, in (with)\n",
            "Crossword clue for ice: Hotel sign. Crossword clue for blood: Kind of a river\n",
            "  Batch 11,000  of  24,054. Loss: 2.6928415298461914.   Elapsed: 0:27:59.\n",
            "Crossword clue for over: Word with time or throw. Crossword clue for April: You happen\n",
            "Crossword clue for cash: Business terms.. Crossword clue for no hit: ___.\n",
            "  Batch 12,000  of  24,054. Loss: 2.3109846115112305.   Elapsed: 0:30:30.\n",
            "Crossword clue for a new: Way to start. Crossword clue for i gave: You ___ you way!!\n",
            "Crossword clue for not as: ___ much (less). Crossword clue for to la: See a business' (wordplay))\n",
            "  Batch 13,000  of  24,054. Loss: 4.262026309967041.   Elapsed: 0:33:01.\n",
            "Crossword clue for wild: 'At 10 a child, at 20 ___'. Crossword clue for play on: On \n",
            "Crossword clue for or not: Believe It ___!\". Crossword clue for right on: Be\n",
            "  Batch 14,000  of  24,054. Loss: 3.523254871368408.   Elapsed: 0:35:32.\n",
            "Crossword clue for hair: Capital growth. Crossword clue for youth team: Not so: In so clue for so: From asword clue for nine. Crossword clue so ofword of itplay a clue the a clue\n",
            "Crossword clue for is try: All we can do. Crossword clue for fire away: Start\n",
            "  Batch 15,000  of  24,054. Loss: 3.030106544494629.   Elapsed: 0:38:04.\n",
            "Crossword clue for cash: Get notes for (wordplay). Crossword clue for step on it: A: One: Cross one: : Crossword clue.'on\n",
            "Crossword clue for ship of state: The nation.. Crossword clue for even so:. Crossword clue for awordplay: : \n",
            "  Batch 16,000  of  24,054. Loss: 3.147129535675049.   Elapsed: 0:40:36.\n",
            "Crossword clue for let: ___ me know. Crossword clue for hold: The: See that\".\n",
            "Crossword clue for so this is it: \"I guess the moment has finally arrived\". Crossword clue for arts: \": Kind for to it: ___)\n",
            "  Batch 17,000  of  24,054. Loss: 2.3699779510498047.   Elapsed: 0:43:07.\n",
            "Crossword clue for sort: Kind. Crossword clue for later:word clue inword clue up orword clue it\n",
            "Crossword clue for go for broke: Bet it all. Crossword clue for car at: '. Cross ___ one andword clue a_. Crossword clue for a audience.word clue for it (word clue\n",
            "  Batch 18,000  of  24,054. Loss: 1.8387130498886108.   Elapsed: 0:45:39.\n",
            "Crossword clue for race: Course.. Crossword clue for where: See one\n",
            "Crossword clue for meet: Face in match play. Crossword clue for spot: Take: have it or on\n",
            "  Batch 19,000  of  24,054. Loss: 3.737316608428955.   Elapsed: 0:48:10.\n",
            "Crossword clue for court: Match box (wordplay). Crossword clue for reason: Words. Crossword for a to\")\n",
            "Crossword clue for of it: 'By the look ___...'. Crossword clue for other: \"_.. Cross clue for us: It I it: Noword clue forword clue for all: 'Of: Kind\n",
            "  Batch 20,000  of  24,054. Loss: 3.2763314247131348.   Elapsed: 0:50:42.\n",
            "Crossword clue for Blue Moon: Once in there, not of ten (wordplay). Crossword clue for upon: Make!\"\n",
            "Crossword clue for a loss: At - for words. Crossword clue for start to:'good in of to the\n",
            "  Batch 21,000  of  24,054. Loss: 3.2161500453948975.   Elapsed: 0:53:13.\n",
            "Crossword clue for next: Coming up after the break. Crossword clue for previous: Not\n",
            "Crossword clue for step no: ___ further (\"Stay right there!\"). Crossword clue for any time: \"\n",
            "  Batch 22,000  of  24,054. Loss: 3.265608072280884.   Elapsed: 0:55:44.\n",
            "Crossword clue for happening: Coming to pass. Crossword clue for everybody else: ___\n",
            "Crossword clue for Australia: Largest island in the world. Crossword clue for and: Is up\n",
            "  Batch 23,000  of  24,054. Loss: 2.547556161880493.   Elapsed: 0:58:15.\n",
            "Crossword clue for worth: Throw (anagram). Crossword clue for its: '\n",
            "Crossword clue for let me: In  hit. Crossword clue for metal: ___ for it: Son, way the that a: Be way \"\n",
            "  Batch 24,000  of  24,054. Loss: 3.185145378112793.   Elapsed: 1:00:47.\n",
            "Crossword clue for is m: It might come after sex. Crossword clue for as is: ___\n",
            "Crossword clue for win: Come out ahead. Crossword clue for right now: Jesus Jones: At (\n",
            "\n",
            "  Average training loss: 2.80\n",
            "  Training epoch took: 1:01:59\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.57\n",
            "  Validation took: 0:03:11\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch 1,000  of  47,375. Loss: 1.6313707828521729.   Elapsed: 0:02:31.\n",
            "Crossword clue for i see: ___ it to a way\n",
            "Crossword clue for first class: Like!'\n",
            "  Batch 2,000  of  47,375. Loss: 1.4206427335739136.   Elapsed: 0:05:02.\n",
            "Crossword clue for eye: ___\n",
            "Crossword clue for half past: The it. \n",
            "  Batch 3,000  of  47,375. Loss: 1.2774733304977417.   Elapsed: 0:07:33.\n",
            "Crossword clue for step:::.: the: off I: ___ a\n",
            "Crossword clue for is one: ___ up ___ at: off for so a be (:: an ___)\n",
            "  Batch 4,000  of  47,375. Loss: 1.017877221107483.   Elapsed: 0:10:05.\n",
            "Crossword clue for also: Not this for is name\"\n",
            "Crossword clue for great: Have \n",
            "  Batch 5,000  of  47,375. Loss: 1.0128600597381592.   Elapsed: 0:12:37.\n",
            "Crossword clue for street: Where\n",
            "Crossword clue for here: \"___ it \n",
            "  Batch 6,000  of  47,375. Loss: 1.7242189645767212.   Elapsed: 0:15:09.\n",
            "Crossword clue for meet me: '___ the (wordplay)'\n",
            "Crossword clue for master work: One with in go\n",
            "  Batch 7,000  of  47,375. Loss: 1.5356484651565552.   Elapsed: 0:17:41.\n",
            "Crossword clue for say so: In as withwordplay\n",
            "Crossword clue for if you can: \"___ awordplay \n",
            "  Batch 8,000  of  47,375. Loss: 1.531371831893921.   Elapsed: 0:20:14.\n",
            "Crossword clue for on the spot:'other in ___ \n",
            "Crossword clue for i do: Like in\n",
            "  Batch 9,000  of  47,375. Loss: 1.8744986057281494.   Elapsed: 0:22:46.\n",
            "Crossword clue for going at: The a a___ in light it\n",
            "Crossword clue for US is: It a in \n",
            "  Batch 10,000  of  47,375. Loss: 1.3594948053359985.   Elapsed: 0:25:19.\n",
            "Crossword clue for own: Words\n",
            "Crossword clue for up to speed: \"wordplay)):)\n",
            "  Batch 11,000  of  47,375. Loss: 1.347726583480835.   Elapsed: 0:27:52.\n",
            "Crossword clue for cash:!\" in:, not: Not:.\n",
            "Crossword clue for greater: ___. of start: (\n"
          ]
        }
      ],
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    if epoch_i == 0:\n",
        "      train_dataloader = train_dataloader_analogy\n",
        "      space = \" \"\n",
        "      prev_loss = 0\n",
        "    else:\n",
        "      train_dataloader = train_dataloader_single\n",
        "      space = \"\"\n",
        "      prev_loss = avg_train_loss\n",
        "\n",
        "    # train_dataloader = train_dataloader_single\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            for i, sample_input in enumerate(b_input_ids):\n",
        "                text = tokenizer.decode(sample_input, skip_special_tokens=True)\n",
        "                try:\n",
        "                    substring = str(tokenizer.encode(re.search(space + \"Crossword clue for .*:\", text)[0][1:])[1:])[1:-1]\n",
        "                except:\n",
        "                    print(\"No substring. Current example: \", text)\n",
        "                tensor_list = [num.item() for num in sample_input]\n",
        "                start_index = str(tensor_list).rfind(substring)\n",
        "                end_index = start_index + len(substring)\n",
        "                input_string = str(tensor_list)[1:end_index]\n",
        "                input_list = [int(num) for num in input_string.strip().split(\",\")]\n",
        "                inputs = torch.tensor(input_list).view(1,len(input_list)).to(device)\n",
        "                outputs = model.generate( \n",
        "                        inputs=inputs,\n",
        "                        do_sample=True,   \n",
        "                        top_k=50, \n",
        "                        max_new_tokens = 30,\n",
        "                        top_p=0.95, \n",
        "                        num_return_sequences=1,\n",
        "                        pad_token_id=tokenizer.eos_token_id)\n",
        "                print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    torch.save({\n",
        "    'epoch': epoch_i,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'scheduler': scheduler.state_dict(),\n",
        "    'loss': loss\n",
        "    }, checkpoints + \"clue_generator_{}_{}\".format(model_str.replace(\"/\", \"\"), epoch_i) + \".pt\")\n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dev_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(dev_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "id": "3b94ac50-9e40-4200-a83a-133dab85d1ad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJUEbHU13q6_"
      },
      "outputs": [],
      "source": [],
      "id": "YJUEbHU13q6_"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}