{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16csfcJ2TNd9",
        "outputId": "e7f2aacf-ee39-476d-905f-787fff83e8b0"
      },
      "id": "16csfcJ2TNd9",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7XlS7hhWXN2",
        "outputId": "0c3aec2c-6283-4080-b409-dcc5bcf8daa5"
      },
      "id": "X7XlS7hhWXN2",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 89.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 57.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d8ae4659-c947-43a9-ab5b-7668435d297d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ae4659-c947-43a9-ab5b-7668435d297d",
        "outputId": "8a819bb3-4422-46a0-bacd-ad39f3514382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import regex as re\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "torch.manual_seed(14)\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "import nltk\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "nltk.download('punkt')\n",
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/Crossword-Generator/'"
      ],
      "metadata": {
        "id": "1zU_iuEdX5JX"
      },
      "id": "1zU_iuEdX5JX",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "63447a12-4d2f-4880-b929-2e3d738880f3",
      "metadata": {
        "id": "63447a12-4d2f-4880-b929-2e3d738880f3"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(path+\"train.csv\")\n",
        "dev = pd.read_csv(path+\"valid.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eac700fc-9691-46f0-a776-287179f5b50e",
      "metadata": {
        "id": "eac700fc-9691-46f0-a776-287179f5b50e"
      },
      "outputs": [],
      "source": [
        "cache_dir = path + \"tmp/\"\n",
        "checkpoints = path + \"checkpoints/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f158b5c8-17b3-4a66-9b98-a3684a1cc590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f158b5c8-17b3-4a66-9b98-a3684a1cc590",
        "outputId": "c034449b-b05e-48ca-a9a0-89c49265126a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>', cache_dir=cache_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "aa7db6f0-e7c6-433f-99c5-46749d72f9bd",
      "metadata": {
        "id": "aa7db6f0-e7c6-433f-99c5-46749d72f9bd"
      },
      "outputs": [],
      "source": [
        "config = GPT2Config.from_pretrained(\"gpt2\", cache_dir=cache_dir)\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", cache_dir=cache_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.resize_token_embeddings(len(tokenizer))\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi8Jn87ceuoX",
        "outputId": "cd251b72-6cb5-4b04-8ed6-ecff532ec577"
      },
      "id": "zi8Jn87ceuoX",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50259, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e8931d6a-65f0-4b59-84e8-80344ed9f71a",
      "metadata": {
        "id": "e8931d6a-65f0-4b59-84e8-80344ed9f71a"
      },
      "outputs": [],
      "source": [
        "train_list_analogy = []\n",
        "analogy_length = 10000\n",
        "for i in range(0, analogy_length, 2):\n",
        "    try:\n",
        "        train_list_analogy.append(\"Crossword clue for \" + train[\"answer\"][i] + \": \" + train[\"clue\"][i] + \". Crossword clue for \" + train[\"answer\"][i+1] + \": \" + train[\"clue\"][i+1])\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_list_single = []\n",
        "num_train_examples = int(len(train)/20)  # = len(train) if using all data\n",
        "for i in range(analogy_length, num_train_examples, 1):\n",
        "    try:\n",
        "        train_list_single.append(\"Crossword clue for \" + train[\"answer\"][i] + \": \" + train[\"clue\"][i])\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "LLoQP74icJNF"
      },
      "id": "LLoQP74icJNF",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_list = []\n",
        "num_dev_examples = int(len(dev)/2)  # = len(dev) if using all data\n",
        "for i in range(num_dev_examples):\n",
        "    try:\n",
        "        dev_list.append(\"Crossword clue for \" + dev[\"answer\"][i] + \": \" + dev[\"clue\"][i])\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "6j8q1DJbXbZZ"
      },
      "id": "6j8q1DJbXbZZ",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f9258d49-67e4-4a76-9128-433bb144110b",
      "metadata": {
        "id": "f9258d49-67e4-4a76-9128-433bb144110b"
      },
      "outputs": [],
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, txt_list, tokenizer, max_length=30):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "\n",
        "        for txt in txt_list:\n",
        "\n",
        "            encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fde3e125-fc23-43e2-9515-252ddb86363c",
      "metadata": {
        "id": "fde3e125-fc23-43e2-9515-252ddb86363c"
      },
      "outputs": [],
      "source": [
        "train_dataset_analogy = GPT2Dataset(train_list_analogy, tokenizer)\n",
        "train_dataset_single = GPT2Dataset(train_list_single, tokenizer)\n",
        "dev_dataset = GPT2Dataset(dev_list, tokenizer)\n",
        "\n",
        "train_dataloader_analogy = DataLoader(\n",
        "            train_dataset_analogy,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset_analogy), # Select batches randomly\n",
        "            batch_size = 2 # Trains with this batch size.\n",
        "        )\n",
        "train_dataloader_single = DataLoader(\n",
        "            train_dataset_single,\n",
        "            sampler = RandomSampler(train_dataset_single),\n",
        "            batch_size = 2\n",
        "        )\n",
        "dev_dataloader = DataLoader(\n",
        "            dev_dataset,\n",
        "            sampler = RandomSampler(dev_dataset),\n",
        "            batch_size = 2\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8e39584c-b6fb-451c-9008-c0aeda8b138d",
      "metadata": {
        "id": "8e39584c-b6fb-451c-9008-c0aeda8b138d"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "total_steps = len(train_dataset_analogy) + len(train_dataset_single) * (epochs-1)\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "35e131ad-f625-45aa-8b62-636a4d8aa0af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35e131ad-f625-45aa-8b62-636a4d8aa0af",
        "outputId": "5fd11b0a-a679-48a4-a0c6-fc67256f4ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "metadata": {
        "id": "GCnKIcYNWs_5"
      },
      "id": "GCnKIcYNWs_5",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3b94ac50-9e40-4200-a83a-133dab85d1ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3b94ac50-9e40-4200-a83a-133dab85d1ad",
        "outputId": "902a47ad-11dc-4c37-860d-c4ae12dff49e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch 1,000  of  2,500. Loss: 4.102136611938477.   Elapsed: 0:00:49.\n",
            "Crossword clue for ochs: I Ain't Marchin' Anymore singer Phil. Crossword clue for suede: It may have been named after a specific organization, for example\n",
            "Crossword clue for on our: Were  way. Crossword clue for used: Not used\n",
            "  Batch 2,000  of  2,500. Loss: 3.158217668533325.   Elapsed: 0:01:36.\n",
            "Crossword clue for learner: A fellow who wins pounds, though just a novice. Crossword clue for snap: Sound from a car\n",
            "Crossword clue for lies: Some stories. Crossword clue for autopsy: Part of a large body\n",
            "\n",
            "  Average training loss: 3.77\n",
            "  Training epoch took: 0:02:00\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.91\n",
            "  Validation took: 0:14:09\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch 1,000  of  155,507. Loss: 1.939148187637329.   Elapsed: 0:00:47.\n",
            "Crossword clue for notorious: ___ the people (pronunciation)\n",
            "Crossword clue for thicc: Like a big-haired, hard-motorcycle\n",
            "  Batch 2,000  of  155,507. Loss: 1.4681683778762817.   Elapsed: 0:01:34.\n",
            "Crossword clue for clements: See 2 Down\n",
            "Crossword clue for has only one: Has nothing to lose\n",
            "  Batch 3,000  of  155,507. Loss: 1.5331929922103882.   Elapsed: 0:02:20.\n",
            "Crossword clue for e ne: 'That's ___ ___' song\n",
            "Crossword clue for import: \"Hacks!\"\n",
            "  Batch 4,000  of  155,507. Loss: 1.977898120880127.   Elapsed: 0:03:07.\n",
            "Crossword clue for one off: Was very small place for it\n",
            "Crossword clue for stigma: \"Everything About What the first time I don't give it\n",
            "  Batch 5,000  of  155,507. Loss: 1.5159878730773926.   Elapsed: 0:03:54.\n",
            "Crossword clue for leap year: See 11 Across\n",
            "Crossword clue for limo: Like some bells\n",
            "  Batch 6,000  of  155,507. Loss: 2.3893446922302246.   Elapsed: 0:04:41.\n",
            "Crossword clue for wee: Un ___ Y\n",
            "Crossword clue for omitter: ___ at the French abbreviation\n",
            "  Batch 7,000  of  155,507. Loss: 1.4776077270507812.   Elapsed: 0:05:28.\n",
            "Crossword clue for Poe: 'The Mr Burns' name, 'The ___'\n",
            "Crossword clue for milky: One's name\n",
            "  Batch 8,000  of  155,507. Loss: 1.418739676475525.   Elapsed: 0:06:15.\n",
            "Crossword clue for nine: \"You\" (wordplay)\n",
            "Crossword clue for in die: \"Oise it!\"\n",
            "  Batch 9,000  of  155,507. Loss: 1.5100224018096924.   Elapsed: 0:07:01.\n",
            "Crossword clue for de mille: She goes\n",
            "Crossword clue for pee: ___ the first-\n",
            "  Batch 10,000  of  155,507. Loss: 2.0923736095428467.   Elapsed: 0:07:48.\n",
            "Crossword clue for weans: The ___ of the New England.\n",
            "Crossword clue for i see: ... and\"\n",
            "  Batch 11,000  of  155,507. Loss: 2.2445831298828125.   Elapsed: 0:08:35.\n",
            "Crossword clue for Paine: '___'\n",
            "Crossword clue for edo: Certain Yankee player\n",
            "  Batch 12,000  of  155,507. Loss: 3.1838200092315674.   Elapsed: 0:09:22.\n",
            "Crossword clue for Falls: They might come up for a jolly!\n",
            "Crossword clue for Vista: Like the cake\n",
            "  Batch 13,000  of  155,507. Loss: 1.2329310178756714.   Elapsed: 0:10:08.\n",
            "Crossword clue for drain pipes: Makes old Englishmen\n",
            "Crossword clue for pewit: 'The ___ Wreath'\n",
            "  Batch 14,000  of  155,507. Loss: 1.8712669610977173.   Elapsed: 0:10:55.\n",
            "Crossword clue for stretch: Stows, in a way\n",
            "Crossword clue for croc: Londondond. \n",
            "  Batch 15,000  of  155,507. Loss: 1.6351189613342285.   Elapsed: 0:11:42.\n",
            "Crossword clue for ceo: C. E. F. P. ___ (anagram)\n",
            "Crossword clue for reissues: L'Arling\n",
            "  Batch 16,000  of  155,507. Loss: 1.1200103759765625.   Elapsed: 0:12:29.\n",
            "Crossword clue for guy: \"I'd make one not much about?\"\n",
            "Crossword clue for Marot: 'T.Y.S.M.S.S.F.S.S.I.B.S.T.F.\n",
            "  Batch 17,000  of  155,507. Loss: 1.4415490627288818.   Elapsed: 0:13:16.\n",
            "Crossword clue for loo: River in England\n",
            "Crossword clue for elbow grease: What a bee may get fast in the arty\n",
            "  Batch 18,000  of  155,507. Loss: 1.4982951879501343.   Elapsed: 0:14:02.\n",
            "Crossword clue for eek: Beards of (wordplay)\n",
            "Crossword clue for to il: Like some TV\n",
            "  Batch 19,000  of  155,507. Loss: 1.7648171186447144.   Elapsed: 0:14:49.\n",
            "Crossword clue for riverman: Follower of a sort.\n",
            "Crossword clue for anomaly: Start of a famous quip\n",
            "  Batch 20,000  of  155,507. Loss: 1.6508598327636719.   Elapsed: 0:15:36.\n",
            "Crossword clue for stood up to: Papped\n",
            "Crossword clue for animal preserves: W.C.B. \n",
            "  Batch 21,000  of  155,507. Loss: 1.6875653266906738.   Elapsed: 0:16:22.\n",
            "Crossword clue for snowfall: Type of soup\n",
            "Crossword clue for pewit: Fictional sea: Its last name of the N.Y.A. has a state of W.W. II's '___'\n",
            "  Batch 22,000  of  155,507. Loss: 1.3405505418777466.   Elapsed: 0:17:09.\n",
            "Crossword clue for parse: Slasher. \n",
            "Crossword clue for auk: ___ Cen, Scottish\n",
            "  Batch 23,000  of  155,507. Loss: 1.3966407775878906.   Elapsed: 0:17:56.\n",
            "Crossword clue for OTC: Green Men (wordplay)\n",
            "Crossword clue for optics: One for the Three time... and how I'm heard\n",
            "  Batch 24,000  of  155,507. Loss: 1.9696158170700073.   Elapsed: 0:18:43.\n",
            "Crossword clue for angelisnobody in: Part 1.\n",
            "Crossword clue for Loner: Actress.\n",
            "  Batch 25,000  of  155,507. Loss: 1.3320368528366089.   Elapsed: 0:19:30.\n",
            "Crossword clue for masses: Underwear them\n",
            "Crossword clue for shallow: Nautose\n",
            "  Batch 26,000  of  155,507. Loss: 1.482170581817627.   Elapsed: 0:20:16.\n",
            "Crossword clue for growth: Word from a bad body, maybe\n",
            "Crossword clue for aces: Is this part to get in his tail? (wordplay)\n",
            "  Batch 27,000  of  155,507. Loss: 1.483893871307373.   Elapsed: 0:21:03.\n",
            "Crossword clue for Leafs: U.K.O. \n",
            "Crossword clue for reed: Emulate an oldly\n",
            "  Batch 28,000  of  155,507. Loss: 2.1461009979248047.   Elapsed: 0:21:50.\n",
            "Crossword clue for nine: Number in two sides of bells\n",
            "Crossword clue for islas: The Italian family, say\n",
            "  Batch 29,000  of  155,507. Loss: 2.201201915740967.   Elapsed: 0:22:37.\n",
            "Crossword clue for Lidon: A small form. \n",
            "Crossword clue for posse: Rode. \n",
            "  Batch 30,000  of  155,507. Loss: 1.8817273378372192.   Elapsed: 0:23:24.\n",
            "Crossword clue for man of: They're up, and it's the ground\n",
            "Crossword clue for tempts fate: Goes to help\n",
            "  Batch 31,000  of  155,507. Loss: 1.5293800830841064.   Elapsed: 0:24:10.\n",
            "Crossword clue for nerves: Narrow of New York \n",
            "Crossword clue for authoritarian: Like a book, maybe\n",
            "  Batch 32,000  of  155,507. Loss: 1.7247799634933472.   Elapsed: 0:24:57.\n",
            "Crossword clue for ivey: Burtic, as a borer\n",
            "Crossword clue for ale: Omelet\n",
            "  Batch 33,000  of  155,507. Loss: 2.551213502883911.   Elapsed: 0:25:44.\n",
            "Crossword clue for bonami: Gobi's '___ You'\n",
            "Crossword clue for Hedy: Reunion\n",
            "  Batch 34,000  of  155,507. Loss: 1.2994892597198486.   Elapsed: 0:26:31.\n",
            "Crossword clue for sneered: Steamed a piece of writing \n",
            "Crossword clue for dunce: Word after black or tree\n",
            "  Batch 35,000  of  155,507. Loss: 2.0330164432525635.   Elapsed: 0:27:17.\n",
            "Crossword clue for top: Ship's home, for example abbreviation\n",
            "Crossword clue for margin: Rode. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-be3eb52a4c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mb_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mb_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    if epoch_i == 0:\n",
        "      train_dataloader = train_dataloader_analogy\n",
        "      space = \" \"\n",
        "      prev_loss = 0\n",
        "    else:\n",
        "      train_dataloader = train_dataloader_single\n",
        "      space = \"\"\n",
        "      prev_loss = avg_train_loss\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            for i, sample_input in enumerate(b_input_ids):\n",
        "                text = tokenizer.decode(sample_input, skip_special_tokens=True)\n",
        "                try:\n",
        "                    substring = str(tokenizer.encode(re.search(space + \"Crossword clue for .*:\", text)[0][1:])[1:])[1:-1]\n",
        "                except:\n",
        "                    print(\"No substring. Current example: \", text)\n",
        "                tensor_list = [num.item() for num in sample_input]\n",
        "                start_index = str(tensor_list).rfind(substring)\n",
        "                end_index = start_index + len(substring)\n",
        "                input_string = str(tensor_list)[1:end_index]\n",
        "                input_list = [int(num) for num in input_string.strip().split(\",\")]\n",
        "                inputs = torch.tensor(input_list).view(1,len(input_list)).to(device)\n",
        "                outputs = model.generate( \n",
        "                        inputs=inputs,\n",
        "                        do_sample=True,   \n",
        "                        top_k=50, \n",
        "                        max_new_tokens = 30,\n",
        "                        top_p=0.95, \n",
        "                        num_return_sequences=1,\n",
        "                        pad_token_id=tokenizer.eos_token_id)\n",
        "                print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    torch.save({\n",
        "    'epoch': epoch_i,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'scheduler': scheduler.state_dict(),\n",
        "    'loss': loss\n",
        "    }, checkpoints + \"clue_generator_{}\".format(epoch_i) + \".pt\")\n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dev_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(dev_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}